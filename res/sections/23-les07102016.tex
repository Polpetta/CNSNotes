In public key binding rule the producer includes public key of each content's
(\textit{KeyLocator} field). The router\footnote{Note: PIT entry collapsing
takes PPKD into account}:
\begin{itemize}
  \item Matches \textit{KeyLocator} digest to PPKD in PIT
  \item Verifies signature using \textit{KeyLocator}
  \item No fetching, storing, parsing of public key
\end{itemize}

PIT entry are not collapsed if two requests from different consumers have
different public keys.

But is this secure? If everyone adherence to IKB there is security against
content poisoning. This could be a great deal, because for example a bad router
can be evil and can share poisoned content. So we have to assume:
\begin{itemize}
  \item All nodes abide by IKB
  \item Consumer not malicious
  \item Consumer-facing routers - not malicious
  \item Consumer and the first-hop router link not compromised\footnote{This
because the consumer share a public key with the first hop}
\end{itemize}

This is the workflow for a request:
\begin{enumerate}
  \item Consumer sends interest containing PPKD
  \item Router ensue that the content it's OK (is possible to have keys hash
collision, but it's improbable)
\end{enumerate}

\paragraph*{Optimization} The possible optimizations are:
\begin{itemize}
  \item Include keys in interest (in order to save storage, but it requires
changes to interest \& content structure)
  \item Only AS border routers implement IKB. This will lead to a better
performance, but it can suffer possible attacks within AS, detectable by
border routers though. The verification can be done only in the border of the
ISP, and not in every router.
  \item Self-Certifying Name (SCN)\footnote{Suppose the consumer before having
the content already has the hash of the content. In a website, for example
links could have not only the links, but also a hash of the content. This is an
example of a catalog/a manifest. Once verified the main page implicitly all the
content inside the website is verified. This is called \textbf{Merkle Tree}}.
Hash of content (including name) as last component of name. This works for
simple kind of content.
  \item Benign consumers use SCN so the network delivers "valid" content
  \item No signature verification by routers, because only one hash
re-computation is needed. But they need to do it for integrity purpose.
\end{itemize}

This lead to a \textbf{Catalogs/Manifests}. You can see a website as a tree,
where only the root is signed, and the nodes/leafs are implicitly verified from
the root. This approach it's OK for static content, but not for dynamic
content, because if a content changes, you have to resign the whole branch of
the tree.
Manifests are always signed and contains pointers to other content. The router
are completely unaware of this structure, only the consumer and producer know
it.
So there are two types of traffic:
\begin{itemize}
  \item Static Content
  \item Interactive Traffic
  \begin{itemize}
    \item Content generate on demand (real-time), e.g. audio/video conferencing
    \item Catalogs are not available
  \end{itemize}
\end{itemize}

\paragraph*{NACK} In CCN when a router realized that a PIT entry expired the
router just delete it, and it will not generate it. Errors messages are a big
problem (we will see later why). When a Consumer asks for a content to the
producer that doesn't exists it shouldn't do anything, but when it sees that
the consumer misspell the address of a requests, the producer can issue a NACK.
This NACK should be signed, but if you signed it routers have to verify it.
If you use self-certified name the consumer have to include the public key in
the interest, so when a NACK is generated by the router this NACK will not be
dropped. Also NACK can be cached.

\section{Fragmentation in CCN and its Security Implication}
Fragmentation it's a networking complication but it has some security aspects.
Internet connects heterogeneous device, over heterogeneous links, with
different:
\begin{itemize}
  \item Physical layers (copper, fiber, radio, laser)
  \item MAC layers
  \item Maximum Transmission Unit (MTUs), that it's determined by MAC layer.
The size of it it's determined by the link layer.
\end{itemize}

A router need to have at least 2 interfaces. It can have different type of
interfaces with different type of MTU, and this could be an issue because if a
MTU it's too bigger for a interface it will not pass.
So the \textbf{fragmentation} is the process of splitting a packet into
fragments that fit into outgoing link MTU.
\begin{itemize}
  \item Fragment header encodes ordering of the specific fragment
  \item Intermediate re-fragmentation can occur if smaller MTU is encountered
\end{itemize}

The fragmentation in IPv4 have some issue:
\begin{itemize}
  \item Several attacks
  \begin{itemize}
    \item Ping of death
    \item Tiny fragment
  \end{itemize}
  \item Router overhead and code complexity
\end{itemize}
This result in a deprecation in IPv6 and limited to source-based fragmentation.

\subsection{Fragmentation in CCN} In CCN there are two messages types:
\begin{enumerate}
  \item Interest message
  \item Content object
\end{enumerate}
In the packets, the name it's not limited. The problem is that maybe you have a
very long name that not fit in a packet, and to have to fragment an interests.

\subsubsection{Interests fragmentation} So how can a router forward the request
if the interest is fragmented?
Intermediate fragmentation \& reassembly for interests is unavoidable. The
router need to wait for all the interest, read the name, split it again and
send to the next \textit{hop}.

When you split a packet of an interest you can number the part of the interest,
and you can compute a signature per segment.

\subsubsection{Content fragmentation} For the content fragmentation, there is
the problem that the router have to cache the same content with different MTU,
and this is something unavoidable.
Also, in today's internet packet fragments might not follow same path. In
CCN/NDN all content fragments \textit{always} follow the same path, but out of
order delivery is possible, event between adjacent routers. Parallel links with
different speeds and/or loss/error.

\paragraph*{FIGOA: Fragmentation with Integrity Guarantees and Optional
Authentication} How can you authenticate a fragment? The source can send
individual segment, but if a intermediary router split another time the router,
it cannot sign it again.
\textbf{FIGOA} supports:
\begin{itemize}
  \item Cut-through switching \& optional intermediate reassembly
  \item Security via \textit{Delayed (Incremental) Authentication}
  \item Also supports integrity with optional authenticity
\end{itemize}
This idea isn't CCN/NDN specific.
To authenticate a fragment you can do in this way: for a very big content you
can split it and put only a portion of the hash in every fragment $H^1$, $H^2$
etc...). When a fragment came to the router he will froward it and wait for the
least one. If the least it's not correctly verified it gets "killed" and not
forwarded. In this way the Consumer will time-out.
Hash is computed gradually and FIGOA works with out-of-order fragments.
With this method, the router can never cheat and send to you fake content.
